{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-09T15:34:28.825568Z",
     "iopub.status.busy": "2024-11-09T15:34:28.825153Z",
     "iopub.status.idle": "2024-11-09T15:34:28.838003Z",
     "shell.execute_reply": "2024-11-09T15:34:28.837149Z",
     "shell.execute_reply.started": "2024-11-09T15:34:28.825531Z"
    },
    "papermill": {
     "duration": 0.040971,
     "end_time": "2023-07-09T11:03:14.845142",
     "exception": false,
     "start_time": "2023-07-09T11:03:14.804171",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\angir\\AppData\\Local\\Temp\\ipykernel_24000\\1013759696.py:11: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\angir\\AppData\\Local\\Temp\\ipykernel_24000\\1013759696.py:11: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()  # For TF 1.x users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T15:34:28.841029Z",
     "iopub.status.busy": "2024-11-09T15:34:28.840298Z",
     "iopub.status.idle": "2024-11-09T15:34:42.431011Z",
     "shell.execute_reply": "2024-11-09T15:34:42.429848Z",
     "shell.execute_reply.started": "2024-11-09T15:34:28.840993Z"
    },
    "papermill": {
     "duration": 18.384105,
     "end_time": "2023-07-09T11:03:33.235029",
     "exception": false,
     "start_time": "2023-07-09T11:03:14.850924",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/angir/Downloads/train_data/train_data\"  # e.g., './dataset/train_data'\n",
    "test_dir = \"C:/Users/angir/Downloads/test_data/test_data\"  # e.g., './dataset/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-11-09T16:27:51.007451Z",
     "iopub.status.idle": "2024-11-09T16:27:51.007769Z",
     "shell.execute_reply": "2024-11-09T16:27:51.007630Z",
     "shell.execute_reply.started": "2024-11-09T16:27:51.007615Z"
    },
    "papermill": {
     "duration": 17.150819,
     "end_time": "2023-07-09T11:03:50.409683",
     "exception": false,
     "start_time": "2023-07-09T11:03:33.258864",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 124 images belonging to 16 classes.\n",
      "Found 26 images belonging to 16 classes.\n",
      "Found 91 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T15:34:51.153632Z",
     "iopub.status.busy": "2024-11-09T15:34:51.153036Z",
     "iopub.status.idle": "2024-11-09T15:34:51.157805Z",
     "shell.execute_reply": "2024-11-09T15:34:51.156825Z",
     "shell.execute_reply.started": "2024-11-09T15:34:51.153605Z"
    },
    "papermill": {
     "duration": 0.013284,
     "end_time": "2023-07-09T11:03:33.253786",
     "exception": false,
     "start_time": "2023-07-09T11:03:33.240502",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='softmax'))  # Adjust to your number of classes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T15:34:51.161202Z",
     "iopub.status.busy": "2024-11-09T15:34:51.160871Z",
     "iopub.status.idle": "2024-11-09T15:34:51.175528Z",
     "shell.execute_reply": "2024-11-09T15:34:51.174664Z",
     "shell.execute_reply.started": "2024-11-09T15:34:51.161148Z"
    },
    "papermill": {
     "duration": 0.016178,
     "end_time": "2023-07-09T11:03:50.431850",
     "exception": false,
     "start_time": "2023-07-09T11:03:50.415672",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step - accuracy: 0.0828 - loss: 2.7797 - val_accuracy: 0.1154 - val_loss: 2.6982\n",
      "Epoch 2/125\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.0312 - loss: 2.8291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0312 - loss: 2.8291 - val_accuracy: 0.1538 - val_loss: 2.7033\n",
      "Epoch 3/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - accuracy: 0.1449 - loss: 2.7131 - val_accuracy: 0.1538 - val_loss: 2.6632\n",
      "Epoch 4/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.1250 - loss: 2.6908 - val_accuracy: 0.1538 - val_loss: 2.6660\n",
      "Epoch 5/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.1289 - loss: 2.6027 - val_accuracy: 0.1538 - val_loss: 2.6234\n",
      "Epoch 6/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1786 - loss: 2.5720 - val_accuracy: 0.1538 - val_loss: 2.6473\n",
      "Epoch 7/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.1877 - loss: 2.5932 - val_accuracy: 0.2308 - val_loss: 2.6568\n",
      "Epoch 8/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1875 - loss: 2.5167 - val_accuracy: 0.2692 - val_loss: 2.7473\n",
      "Epoch 9/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.1953 - loss: 2.3845 - val_accuracy: 0.2308 - val_loss: 2.9139\n",
      "Epoch 10/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1875 - loss: 2.5774 - val_accuracy: 0.2692 - val_loss: 2.6952\n",
      "Epoch 11/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2474 - loss: 2.2909 - val_accuracy: 0.1923 - val_loss: 2.4731\n",
      "Epoch 12/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1786 - loss: 2.3507 - val_accuracy: 0.2692 - val_loss: 2.4402\n",
      "Epoch 13/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2429 - loss: 2.3262 - val_accuracy: 0.3077 - val_loss: 2.4171\n",
      "Epoch 14/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 974ms/step - accuracy: 0.2500 - loss: 2.1975 - val_accuracy: 0.3077 - val_loss: 2.5152\n",
      "Epoch 15/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2120 - loss: 2.3313 - val_accuracy: 0.2692 - val_loss: 2.5235\n",
      "Epoch 16/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 2.5088 - val_accuracy: 0.3077 - val_loss: 2.3169\n",
      "Epoch 17/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2921 - loss: 2.2399 - val_accuracy: 0.3462 - val_loss: 2.2525\n",
      "Epoch 18/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 999ms/step - accuracy: 0.3438 - loss: 2.0564 - val_accuracy: 0.4231 - val_loss: 2.3044\n",
      "Epoch 19/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5s/step - accuracy: 0.3419 - loss: 2.1344 - val_accuracy: 0.3077 - val_loss: 2.4312\n",
      "Epoch 20/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.2812 - loss: 2.0988 - val_accuracy: 0.2308 - val_loss: 2.4196\n",
      "Epoch 21/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3131 - loss: 2.1787 - val_accuracy: 0.2692 - val_loss: 2.2917\n",
      "Epoch 22/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 991ms/step - accuracy: 0.2188 - loss: 2.1195 - val_accuracy: 0.3462 - val_loss: 2.4102\n",
      "Epoch 23/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3395 - loss: 1.9737 - val_accuracy: 0.3462 - val_loss: 2.2177\n",
      "Epoch 24/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1875 - loss: 2.2734 - val_accuracy: 0.3462 - val_loss: 2.1876\n",
      "Epoch 25/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5s/step - accuracy: 0.2772 - loss: 2.0956 - val_accuracy: 0.2692 - val_loss: 2.2373\n",
      "Epoch 26/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 991ms/step - accuracy: 0.3438 - loss: 1.8914 - val_accuracy: 0.3462 - val_loss: 2.1824\n",
      "Epoch 27/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.5018 - loss: 1.7091 - val_accuracy: 0.3462 - val_loss: 2.3842\n",
      "Epoch 28/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.4062 - loss: 1.8854 - val_accuracy: 0.3846 - val_loss: 2.3757\n",
      "Epoch 29/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6s/step - accuracy: 0.4244 - loss: 1.6894 - val_accuracy: 0.3077 - val_loss: 2.5514\n",
      "Epoch 30/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3125 - loss: 1.9037 - val_accuracy: 0.3462 - val_loss: 2.4772\n",
      "Epoch 31/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12s/step - accuracy: 0.5357 - loss: 1.4997 - val_accuracy: 0.3846 - val_loss: 2.2760\n",
      "Epoch 32/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4062 - loss: 1.8602 - val_accuracy: 0.3077 - val_loss: 2.3224\n",
      "Epoch 33/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12s/step - accuracy: 0.4766 - loss: 1.5799 - val_accuracy: 0.3462 - val_loss: 2.1430\n",
      "Epoch 34/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4062 - loss: 1.5427 - val_accuracy: 0.3462 - val_loss: 1.9991\n",
      "Epoch 35/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11s/step - accuracy: 0.5273 - loss: 1.5207 - val_accuracy: 0.4231 - val_loss: 1.8898\n",
      "Epoch 36/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.6429 - loss: 1.2808 - val_accuracy: 0.4615 - val_loss: 1.9877\n",
      "Epoch 37/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12s/step - accuracy: 0.5144 - loss: 1.3846 - val_accuracy: 0.3077 - val_loss: 2.1376\n",
      "Epoch 38/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.5625 - loss: 1.1661 - val_accuracy: 0.2692 - val_loss: 2.2081\n",
      "Epoch 39/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11s/step - accuracy: 0.5283 - loss: 1.2485 - val_accuracy: 0.3462 - val_loss: 2.3110\n",
      "Epoch 40/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.6562 - loss: 1.1471 - val_accuracy: 0.4231 - val_loss: 2.2795\n",
      "Epoch 41/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 11s/step - accuracy: 0.6569 - loss: 1.1029 - val_accuracy: 0.4231 - val_loss: 2.1795\n",
      "Epoch 42/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.5312 - loss: 1.1990 - val_accuracy: 0.4231 - val_loss: 2.4006\n",
      "Epoch 43/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10s/step - accuracy: 0.5328 - loss: 1.1442 - val_accuracy: 0.3077 - val_loss: 2.1465\n",
      "Epoch 44/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7188 - loss: 0.9358 - val_accuracy: 0.3077 - val_loss: 2.2210\n",
      "Epoch 45/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10s/step - accuracy: 0.6458 - loss: 1.0574 - val_accuracy: 0.3846 - val_loss: 2.7318\n",
      "Epoch 46/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.6429 - loss: 0.8918 - val_accuracy: 0.3077 - val_loss: 2.4061\n",
      "Epoch 47/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11s/step - accuracy: 0.7079 - loss: 0.8199 - val_accuracy: 0.3462 - val_loss: 2.8796\n",
      "Epoch 48/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.6875 - loss: 0.8261 - val_accuracy: 0.3846 - val_loss: 2.9145\n",
      "Epoch 49/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11s/step - accuracy: 0.6608 - loss: 1.0602 - val_accuracy: 0.3077 - val_loss: 2.3874\n",
      "Epoch 50/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.5938 - loss: 0.9574 - val_accuracy: 0.3846 - val_loss: 2.4718\n",
      "Epoch 51/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11s/step - accuracy: 0.7083 - loss: 0.7949 - val_accuracy: 0.4615 - val_loss: 2.6980\n",
      "Epoch 52/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.7143 - loss: 0.9999 - val_accuracy: 0.3846 - val_loss: 2.6232\n",
      "Epoch 53/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10s/step - accuracy: 0.8082 - loss: 0.6046 - val_accuracy: 0.3846 - val_loss: 2.7973\n",
      "Epoch 54/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.6875 - loss: 0.8671 - val_accuracy: 0.4615 - val_loss: 3.0895\n",
      "Epoch 55/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11s/step - accuracy: 0.7787 - loss: 0.7799 - val_accuracy: 0.3462 - val_loss: 3.8316\n",
      "Epoch 56/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.9375 - loss: 0.3999 - val_accuracy: 0.2692 - val_loss: 3.8836\n",
      "Epoch 57/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12s/step - accuracy: 0.7535 - loss: 0.7921 - val_accuracy: 0.4231 - val_loss: 3.1080\n",
      "Epoch 58/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.6875 - loss: 0.7739 - val_accuracy: 0.3846 - val_loss: 3.8943\n",
      "Epoch 59/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13s/step - accuracy: 0.6170 - loss: 0.9570 - val_accuracy: 0.5000 - val_loss: 3.1904\n",
      "Epoch 60/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.7812 - loss: 0.6919 - val_accuracy: 0.2308 - val_loss: 2.8893\n",
      "Epoch 61/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12s/step - accuracy: 0.7936 - loss: 0.6587 - val_accuracy: 0.3077 - val_loss: 2.4512\n",
      "Epoch 62/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.8438 - loss: 0.5597 - val_accuracy: 0.3846 - val_loss: 2.9048\n",
      "Epoch 63/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11s/step - accuracy: 0.8563 - loss: 0.6241 - val_accuracy: 0.4615 - val_loss: 3.4981\n",
      "Epoch 64/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.8125 - loss: 0.4903 - val_accuracy: 0.4231 - val_loss: 3.6451\n",
      "Epoch 65/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11s/step - accuracy: 0.8427 - loss: 0.5238 - val_accuracy: 0.3846 - val_loss: 3.9693\n",
      "Epoch 66/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.8750 - loss: 0.2983 - val_accuracy: 0.3462 - val_loss: 3.5784\n",
      "Epoch 67/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11s/step - accuracy: 0.8268 - loss: 0.5692 - val_accuracy: 0.3462 - val_loss: 3.6702\n",
      "Epoch 68/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.8929 - loss: 0.3293 - val_accuracy: 0.4231 - val_loss: 3.5040\n",
      "Epoch 69/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10s/step - accuracy: 0.8834 - loss: 0.3808 - val_accuracy: 0.3462 - val_loss: 3.6645\n",
      "Epoch 70/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.9062 - loss: 0.3605 - val_accuracy: 0.3077 - val_loss: 3.8227\n",
      "Epoch 71/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12s/step - accuracy: 0.8776 - loss: 0.3694 - val_accuracy: 0.3077 - val_loss: 4.0666\n",
      "Epoch 72/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.9286 - loss: 0.2368 - val_accuracy: 0.4231 - val_loss: 3.9462\n",
      "Epoch 73/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4s/step - accuracy: 0.8549 - loss: 0.3081 - val_accuracy: 0.3846 - val_loss: 4.4730\n",
      "Epoch 74/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 913ms/step - accuracy: 0.8750 - loss: 0.2594 - val_accuracy: 0.3077 - val_loss: 4.5520\n",
      "Epoch 75/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6s/step - accuracy: 0.8891 - loss: 0.2600 - val_accuracy: 0.3846 - val_loss: 4.7519\n",
      "Epoch 76/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.8750 - loss: 0.3765 - val_accuracy: 0.3846 - val_loss: 4.4575\n",
      "Epoch 77/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10s/step - accuracy: 0.9042 - loss: 0.2543 - val_accuracy: 0.3846 - val_loss: 4.5074\n",
      "Epoch 78/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.8438 - loss: 0.4371 - val_accuracy: 0.3846 - val_loss: 4.1531\n",
      "Epoch 79/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 11s/step - accuracy: 0.9579 - loss: 0.1717 - val_accuracy: 0.4231 - val_loss: 4.8748\n",
      "Epoch 80/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9375 - loss: 0.1336 - val_accuracy: 0.3846 - val_loss: 5.3619\n",
      "Epoch 81/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11s/step - accuracy: 0.9416 - loss: 0.1944 - val_accuracy: 0.5000 - val_loss: 4.8196\n",
      "Epoch 82/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.9062 - loss: 0.1895 - val_accuracy: 0.3846 - val_loss: 4.4009\n",
      "Epoch 83/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11s/step - accuracy: 0.9675 - loss: 0.1853 - val_accuracy: 0.3846 - val_loss: 5.2651\n",
      "Epoch 84/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.9688 - loss: 0.1934 - val_accuracy: 0.5000 - val_loss: 5.4258\n",
      "Epoch 85/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7s/step - accuracy: 0.9645 - loss: 0.1367 - val_accuracy: 0.3846 - val_loss: 5.0484\n",
      "Epoch 86/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.9688 - loss: 0.1748 - val_accuracy: 0.4231 - val_loss: 5.2837\n",
      "Epoch 87/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6s/step - accuracy: 0.9505 - loss: 0.1597 - val_accuracy: 0.3846 - val_loss: 5.6786\n",
      "Epoch 88/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9643 - loss: 0.1804 - val_accuracy: 0.3077 - val_loss: 5.7466\n",
      "Epoch 89/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step - accuracy: 0.9283 - loss: 0.2587 - val_accuracy: 0.4231 - val_loss: 5.2101\n",
      "Epoch 90/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9688 - loss: 0.1752 - val_accuracy: 0.4615 - val_loss: 5.1523\n",
      "Epoch 91/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6s/step - accuracy: 0.9719 - loss: 0.1256 - val_accuracy: 0.4231 - val_loss: 4.5932\n",
      "Epoch 92/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.8438 - loss: 0.2695 - val_accuracy: 0.4231 - val_loss: 4.9266\n",
      "Epoch 93/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6s/step - accuracy: 0.9570 - loss: 0.1464 - val_accuracy: 0.3846 - val_loss: 5.4784\n",
      "Epoch 94/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8214 - loss: 0.3587 - val_accuracy: 0.4615 - val_loss: 4.8123\n",
      "Epoch 95/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step - accuracy: 0.9850 - loss: 0.0787 - val_accuracy: 0.3077 - val_loss: 5.8601\n",
      "Epoch 96/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8750 - loss: 0.5570 - val_accuracy: 0.4231 - val_loss: 5.6764\n",
      "Epoch 97/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6s/step - accuracy: 0.9533 - loss: 0.1303 - val_accuracy: 0.4231 - val_loss: 5.2571\n",
      "Epoch 98/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8125 - loss: 0.3363 - val_accuracy: 0.4231 - val_loss: 4.7319\n",
      "Epoch 99/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.9369 - loss: 0.1533 - val_accuracy: 0.5000 - val_loss: 6.1088\n",
      "Epoch 100/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 822ms/step - accuracy: 1.0000 - loss: 0.0477 - val_accuracy: 0.4231 - val_loss: 6.6262\n",
      "Epoch 101/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.9309 - loss: 0.1873 - val_accuracy: 0.3462 - val_loss: 4.8287\n",
      "Epoch 102/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 908ms/step - accuracy: 0.9688 - loss: 0.0737 - val_accuracy: 0.3462 - val_loss: 4.9466\n",
      "Epoch 103/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9327 - loss: 0.1816 - val_accuracy: 0.4231 - val_loss: 4.5091\n",
      "Epoch 104/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 899ms/step - accuracy: 0.9375 - loss: 0.1672 - val_accuracy: 0.4615 - val_loss: 5.4643\n",
      "Epoch 105/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9440 - loss: 0.1537 - val_accuracy: 0.4231 - val_loss: 6.2992\n",
      "Epoch 106/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866ms/step - accuracy: 0.9286 - loss: 0.1899 - val_accuracy: 0.4231 - val_loss: 6.2073\n",
      "Epoch 107/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.9795 - loss: 0.0726 - val_accuracy: 0.3462 - val_loss: 6.5950\n",
      "Epoch 108/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817ms/step - accuracy: 0.9688 - loss: 0.2278 - val_accuracy: 0.3846 - val_loss: 6.1498\n",
      "Epoch 109/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.9472 - loss: 0.2148 - val_accuracy: 0.4615 - val_loss: 5.0368\n",
      "Epoch 110/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 932ms/step - accuracy: 0.9688 - loss: 0.0727 - val_accuracy: 0.5000 - val_loss: 5.2043\n",
      "Epoch 111/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9597 - loss: 0.1358 - val_accuracy: 0.5000 - val_loss: 5.8991\n",
      "Epoch 112/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.5000 - val_loss: 5.8592\n",
      "Epoch 113/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9946 - loss: 0.0470 - val_accuracy: 0.4615 - val_loss: 6.3847\n",
      "Epoch 114/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 888ms/step - accuracy: 0.9375 - loss: 0.1004 - val_accuracy: 0.4615 - val_loss: 6.4334\n",
      "Epoch 115/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9650 - loss: 0.1717 - val_accuracy: 0.4231 - val_loss: 6.2537\n",
      "Epoch 116/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 832ms/step - accuracy: 0.9688 - loss: 0.1196 - val_accuracy: 0.3077 - val_loss: 6.1992\n",
      "Epoch 117/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.9850 - loss: 0.0835 - val_accuracy: 0.3846 - val_loss: 5.6229\n",
      "Epoch 118/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 857ms/step - accuracy: 0.9688 - loss: 0.0808 - val_accuracy: 0.4615 - val_loss: 5.6218\n",
      "Epoch 119/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9857 - loss: 0.0546 - val_accuracy: 0.4615 - val_loss: 6.2163\n",
      "Epoch 120/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 834ms/step - accuracy: 0.9643 - loss: 0.1315 - val_accuracy: 0.4231 - val_loss: 5.5569\n",
      "Epoch 121/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.9774 - loss: 0.0970 - val_accuracy: 0.3846 - val_loss: 6.3101\n",
      "Epoch 122/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 827ms/step - accuracy: 0.9688 - loss: 0.0750 - val_accuracy: 0.3462 - val_loss: 5.3977\n",
      "Epoch 123/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9483 - loss: 0.1311 - val_accuracy: 0.5000 - val_loss: 5.8467\n",
      "Epoch 124/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 840ms/step - accuracy: 0.9062 - loss: 0.2060 - val_accuracy: 0.5000 - val_loss: 6.1363\n",
      "Epoch 125/125\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.9123 - loss: 0.1534 - val_accuracy: 0.4615 - val_loss: 7.9664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=125\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T15:34:51.176798Z",
     "iopub.status.busy": "2024-11-09T15:34:51.176533Z",
     "iopub.status.idle": "2024-11-09T15:34:51.186411Z",
     "shell.execute_reply": "2024-11-09T15:34:51.185525Z",
     "shell.execute_reply.started": "2024-11-09T15:34:51.176776Z"
    },
    "papermill": {
     "duration": 0.013723,
     "end_time": "2023-07-09T11:03:50.450518",
     "exception": false,
     "start_time": "2023-07-09T11:03:50.436795",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: saved_models/bird_classifier_model.h5\n"
     ]
    }
   ],
   "source": [
    "# === 7. Save the trained model ===\n",
    "model_save_path = 'saved_models/bird_classifier_model.h5'  # Or any path/folder you prefer\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved at: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = train_generator.num_classes\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    Reshape((150, 150 * 3), input_shape=(150, 150, 3)),\n",
    "    LSTM(256, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_lstm = model_lstm.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "print(\"\\n✅ LSTM Model Evaluation:\")\n",
    "model_lstm.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict with CNN\n",
    "y_pred_cnn = model_cnn.predict(test_generator)\n",
    "y_pred_cnn_classes = np.argmax(y_pred_cnn, axis=1)\n",
    "\n",
    "# Predict with LSTM\n",
    "y_pred_lstm = model_lstm.predict(test_generator)\n",
    "y_pred_lstm_classes = np.argmax(y_pred_lstm, axis=1)\n",
    "\n",
    "# True labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Print first 10 predictions vs actual\n",
    "print(\"\\nFirst 10 CNN Predictions vs Actual:\")\n",
    "print(list(zip(y_pred_cnn_classes[:10], y_true[:10])))\n",
    "\n",
    "print(\"\\nFirst 10 LSTM Predictions vs Actual:\")\n",
    "print(list(zip(y_pred_lstm_classes[:10], y_true[:10])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Found 150 images belonging to 16 classes.\n",
      "\n",
      "✅ Predicted Bird Species: blasti\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === 1. Load the saved model ===+\n",
    "model = load_model('saved_models/bird_classifier_model.h5')\n",
    "\n",
    "# === 2. Load and preprocess your test image ===\n",
    "img_path = 'C:/Users/angir/Downloads/test_data/test_data/blasti/DSC_6411.jpg'  # <--- your image path\n",
    "img = image.load_img(img_path, target_size=(150, 150))  # use (224, 224) if trained with larger images\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0  # normalize\n",
    "img_array = np.expand_dims(img_array, axis=0)  # make shape (1, 150, 150, 3)\n",
    "\n",
    "# === 3. Predict ===\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "# === 4. Load class labels from training data directory ===\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_path = 'C:/Users/angir/Downloads/train_data/train_data'  # <-- your training folder\n",
    "\n",
    "# Create a temp generator just to get class indices\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "temp_generator = datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "class_indices = temp_generator.class_indices\n",
    "labels = dict((v, k) for k, v in class_indices.items())\n",
    "\n",
    "# === 5. Get predicted class label ===\n",
    "predicted_label = labels[predicted_class_index]\n",
    "\n",
    "print(f\"\\n✅ Predicted Bird Species: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 471346,
     "sourceId": 883439,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3540549,
     "sourceId": 6170534,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30527,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
